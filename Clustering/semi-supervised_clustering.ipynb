{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlikely-maple",
   "metadata": {},
   "source": [
    "# Semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-hindu",
   "metadata": {},
   "source": [
    "#### This notebook aims at clustering the dataset using a classifier that is trained on a small portion of the data. It  uses a Residual Network as a classifier. After being trained, it is used to predict the sensitive attribute of the trasining  data and allocates each sample to its corresponding cluster based on its prediction and the sample's class. This notebook can be run sequencially, cell by cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-firewall",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import sys  \n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "\n",
    "import visdom\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity, pairwise_distances\n",
    "\n",
    "sys.path.insert(0, '../Resnet/')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import *\n",
    "from my_ImageFolder import *\n",
    "from fairness_metrics import *\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-seven",
   "metadata": {},
   "source": [
    "# Defining the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_PROTECTED, BIAS, VAL_MODE, START_EPOCH, NUM_EPOCH, SHOW_PROGRESS, ID, DATASET, NUM_TRIALS, BIAS, PROTECTED = 0, 0.8, False, 0, 10, False, 0, \"basket_volley\", 1, 0.8, \"jc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-welding",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bask_r_f = '../Datasets/basket_volley/basket/basket_f_r/'\n",
    "path_bask_y_f = '../Datasets/basket_volley/basket/basket_f_y/'\n",
    "path_bask_r_m = '../Datasets/basket_volley/basket/basket_m_r/'\n",
    "path_bask_y_m = '../Datasets/basket_volley/basket/basket_m_y/'\n",
    "\n",
    "bask_r_f = os.listdir(path_bask_r_f)\n",
    "bask_y_f = os.listdir(path_bask_y_f)\n",
    "bask_r_m = os.listdir(path_bask_r_m)\n",
    "bask_y_m = os.listdir(path_bask_y_m)\n",
    "\n",
    "path_voll_r_f = '../Datasets/basket_volley/volley/volley_f_r/'\n",
    "path_voll_y_f = '../Datasets/basket_volley/volley/volley_f_y/'\n",
    "path_voll_r_m = '../Datasets/basket_volley/volley/volley_m_r/'\n",
    "path_voll_y_m = '../Datasets/basket_volley/volley/volley_m_y/'\n",
    "\n",
    "voll_r_f = os.listdir(path_voll_r_f)\n",
    "voll_y_f = os.listdir(path_voll_y_f)\n",
    "voll_r_m = os.listdir(path_voll_r_m)\n",
    "voll_y_m = os.listdir(path_voll_y_m)\n",
    "\n",
    "class0_min, class1_min = (bask_y_m + bask_y_f, voll_r_m + voll_r_f) if PROTECTED == \"jc\" else (bask_y_f + bask_r_f, voll_r_m + voll_y_m)\n",
    "protected_groups = set(class0_min + class1_min)\n",
    "females = set(bask_r_f + bask_y_f + voll_r_f + voll_y_f)\n",
    "yellow = set(bask_y_f + bask_y_m + voll_y_f + voll_y_m)\n",
    "volley = set(voll_r_f + voll_r_m + voll_y_f + voll_y_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-friendship",
   "metadata": {},
   "source": [
    "## Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GenderFolder(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    This class redefines the ImageFolder class as the weight of each image is returned along with the data and label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, females, embeddings, indexes):\n",
    "        super().__init__(root)\n",
    "        self.females = females\n",
    "        self.embeddings = embeddings\n",
    "        self.indexes = indexes\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        _, label = super().__getitem__(index)\n",
    "        return self.embeddings[label][np.where(self.indexes[label] == index)[0][0]], int(self.samples[index][0].split(\"/\")[-1] in self.females), 1, index\n",
    "    \n",
    "class my_ImageGenderFolder(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    This class redefines the ImageFolder class as the weight of each image is returned along with the data and label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform, group):\n",
    "        super().__init__(root, transform)\n",
    "        self.group = group\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        inp, _ = super().__getitem__(index)\n",
    "        return inp, int(self.samples[index][0].split(\"/\")[-1] in self.group), 1, index\n",
    "    \n",
    "class my_subset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        Subset of a dataset at specified indices.\n",
    "\n",
    "        Arguments:\n",
    "            dataset (Dataset): The whole Dataset\n",
    "            indices (sequence): Indices in the whole set selected for subset\n",
    "        labels(sequence) : targets as required for the indices. will be the same length as indices\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.samples = list(map(dataset.samples.__getitem__, indices))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        return self.dataset[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train_all': transforms.Compose([\n",
    "        # transforms.RandomResizedCrop(224),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = f'../Datasets/basket_volley/train_test_split_{PROTECTED}'\n",
    "image_datasets = {\n",
    "    x: my_ImageGenderFolder(os.path.join(data_dir, f\"train_{BIAS}\" if x == \"train_all\" else x), data_transforms[x], females if PROTECTED == \"gd\" else yellow)\n",
    "    for x in ['train_all', 'test']}\n",
    "\n",
    "split = 0.15\n",
    "indices = balance_indices(image_datasets[\"train_all\"], split)\n",
    "\n",
    "image_datasets[\"train\"] = my_subset(image_datasets[\"train_all\"], indices=indices)\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', \"train_all\", 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', \"train_all\", 'test']}\n",
    "\n",
    "class_names = image_datasets['train_all'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = 0, 0, 0, 0\n",
    "for _, l, _, i in image_datasets[\"train\"]:\n",
    "    v = int(image_datasets[\"train_all\"].samples[i][0].split(\"/\")[-1] in volley)\n",
    "    if not l and not v:\n",
    "        a += 1\n",
    "    if not l and v:\n",
    "        b += 1\n",
    "    if l and not v:\n",
    "        c += 1\n",
    "    if l and v:\n",
    "        d += 1\n",
    "    \n",
    "print(f\"The proportions are: {a}:{b}:{c}:{d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-history",
   "metadata": {},
   "source": [
    "# Defining Resnet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = weighted_cross_entropy_loss  # nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-experience",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_MODE, START_EPOCH, NUM_EPOCH, SHOW_PROGRESS = False, 0, 10, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-wagon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, dataloaders, dataset_sizes,\n",
    "                            device,\n",
    "                            start_epoch=START_EPOCH,\n",
    "                            num_epochs=NUM_EPOCH,\n",
    "                            val_mode=VAL_MODE, show_progress=SHOW_PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-metropolitan",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acc. on small raining set: {float(accuracy(model_conv, device, dataloaders['train']))}\")\n",
    "print(f\"Acc. on all training set: {float(accuracy(model_conv, device, dataloaders['train_all']))}\")\n",
    "print(f\"Acc. on Test set: {float(accuracy(model_conv, device, dataloaders['test']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-salmon",
   "metadata": {},
   "source": [
    "# Build Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans, indices = clustering_1(model_conv, dataloaders[\"train_all\"], image_datasets[\"train_all\"].samples)\n",
    "kmeans = [kmeans[0].reshape((-1)), kmeans[1].reshape((-1))]\n",
    "indices = [indices[0].reshape((-1)), indices[1].reshape((-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_paths_0 = view_clusters(\"class_0/\", kmeans[0], indices[0])\n",
    "cluster_paths_1 = view_clusters(\"class_1/\", kmeans[1], indices[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-baghdad",
   "metadata": {},
   "source": [
    "### Basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(\"class_0/\", cluster_paths_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-standing",
   "metadata": {},
   "source": [
    "### Volley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(\"class_1/\", cluster_paths_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-property",
   "metadata": {},
   "source": [
    "### Saving clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = make_save_dict(image_datasets[\"train_all\"].samples, [kmeans[0], kmeans[1]], [indices[0], indices[1]], save=True, name=\"resnet_jc.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-texas",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader):\n",
    "    model.eval()\n",
    "    corr, total = 0, 0\n",
    "    for inputs, labels, _, _ in dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corr += int(sum(preds == labels))\n",
    "        total += len(preds)\n",
    "    print(\"Accuracy is {}%\".format(corr/total*100))\n",
    "    \n",
    "def clustering_1(model, dataloader, samples):\n",
    "    kmeans = [np.array([]).astype(int).reshape((0,1)) , np.array([]).astype(int).reshape((0,1))]\n",
    "    indexes = [np.array([]).astype(int).reshape((0,1)) , np.array([]).astype(int).reshape((0,1))]\n",
    "\n",
    "    for inputs, labels, _, indices in dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1) \n",
    "        for j, l in enumerate(labels):\n",
    "            index = int(samples[indices[j]][0].split(\"/\")[-1] in volley)\n",
    "            \n",
    "            kmeans[index] = np.concatenate([kmeans[index], preds[j].numpy().reshape((1, -1))])\n",
    "            indexes[index] = np.concatenate([indexes[index], indices[j].numpy().reshape((1, -1))])\n",
    "            \n",
    "    return kmeans, indexes\n",
    "\n",
    "def clustering_2(model, transforms):\n",
    "    kmeans = [[] for _ in range(len(transforms))]\n",
    "    indexes = [np.array([]).astype(int), np.array([]).astype(int)]\n",
    "\n",
    "    for label in range(len(transforms)):\n",
    "        for emb in transforms[label]:\n",
    "            emb = torch.tensor(emb).reshape((1, -1))\n",
    "            outputs = model(emb)\n",
    "            _, pred = torch.max(outputs, 1) \n",
    "            kmeans[label].append(int(pred))\n",
    "    return kmeans\n",
    "\n",
    "def view_clusters(path, kmeans, indexes):\n",
    "    K = len(set(kmeans))\n",
    "    \n",
    "    paths = []\n",
    "    for k in range(K):\n",
    "        paths.append(os.path.join(path, f\"clustering_{K}/cluster_{k}\"))\n",
    "        os.makedirs(paths[-1], exist_ok=True)\n",
    "        \n",
    "    for i in range(len(kmeans)):\n",
    "        src = image_datasets[\"train_all\"].samples[indexes[i]][0]\n",
    "        dst = os.path.join(path, f\"clustering_{K}/cluster_{kmeans[i]}/\") + src.split(\"/\")[-1]\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def make_save_dict(samples, k_means_list, indexes_list, save=False, name=\"dict.txt\"):\n",
    "    dic = {}\n",
    "    for k_means, indexes in zip(k_means_list, indexes_list):\n",
    "        for cluster, idx in zip(k_means, indexes):\n",
    "            img = samples[idx][0].split(\"/\")[-1]\n",
    "            dic[img] = cluster\n",
    "       \n",
    "    if save:\n",
    "        f = open(name, \"a\")\n",
    "        f.write(str(dic))\n",
    "        f.close()\n",
    "    \n",
    "    return dic\n",
    "\n",
    "def balance_indices(dataset, p):\n",
    "    c00, c01, c10, c11, indices = 0, 0, 0, 0, []\n",
    "    thres, it = len(dataset)*p/4, iter(dataset)\n",
    "\n",
    "    while c00 < thres or c01 < thres or c10 < thres or c11 < thres:\n",
    "        _, l, _, i = next(it)\n",
    "        v = int(dataset.samples[i][0].split(\"/\")[-1] in volley)\n",
    "        \n",
    "        if l and v and c11 < thres:\n",
    "            c11 += 1\n",
    "            indices.append(i)\n",
    "        elif l and not v and c01 < thres:\n",
    "            c01 += 1\n",
    "            indices.append(i)\n",
    "        elif not l and v and c10 < thres:\n",
    "            c10 += 1\n",
    "            indices.append(i)\n",
    "        elif not l and not v and c00 < thres:\n",
    "            c00 += 1\n",
    "            indices.append(i)\n",
    "        \n",
    "    return indices\n",
    "            \n",
    "\n",
    "def statistics(path, clusters):\n",
    "    K = len(set(clusters))\n",
    "    \n",
    "    for k in range(K):\n",
    "        n_bask, n_voll, n_r, n_y, n_m, n_f = 0, 0, 0, 0, 0, 0\n",
    "        cluster = os.listdir(clusters[k])\n",
    "        for img in cluster:\n",
    "            if img in bask_r_f:\n",
    "                n_bask += 1\n",
    "                n_f += 1\n",
    "                n_r += 1\n",
    "                \n",
    "            if img in bask_r_m:\n",
    "                n_bask += 1\n",
    "                n_m += 1\n",
    "                n_r += 1\n",
    "                \n",
    "            if img in bask_y_f:\n",
    "                n_bask += 1\n",
    "                n_f += 1\n",
    "                n_y += 1\n",
    "            \n",
    "            if img in bask_y_m:\n",
    "                n_bask += 1\n",
    "                n_m += 1\n",
    "                n_y += 1\n",
    "            \n",
    "            if img in voll_r_f:\n",
    "                n_voll += 1\n",
    "                n_f += 1\n",
    "                n_r += 1\n",
    "            \n",
    "            if img in voll_r_m:\n",
    "                n_voll += 1\n",
    "                n_m += 1\n",
    "                n_r += 1\n",
    "                \n",
    "            if img in voll_y_f:\n",
    "                n_voll += 1\n",
    "                n_f += 1\n",
    "                n_y += 1\n",
    "            \n",
    "            if img in voll_y_m:\n",
    "                n_voll += 1\n",
    "                n_m += 1\n",
    "                n_y += 1\n",
    "                \n",
    "        \n",
    "        print(f\"--------------Cluster {k}--------- \\n n. samples: {len(cluster)}\\n n. of bask: {n_bask} ({n_bask/len(cluster)*100:.1f}%)\\n n. of volley: {n_voll} ({n_voll/len(cluster)*100:.1f}%)\\n n. of red: {n_r} ({n_r/len(cluster)*100:.1f}%)\\n n. of yellow: {n_y} ({n_y/len(cluster)*100:.1f}%)\\n n. of males: {n_m} ({n_m/len(cluster)*100:.1f}%)\\n n. of females: {n_f} ({n_f/len(cluster)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
