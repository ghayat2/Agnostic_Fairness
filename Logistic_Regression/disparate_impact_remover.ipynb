{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alone-bermuda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport logistic_regression_model\n",
    "%aimport load_dataset\n",
    "%aimport fairness_metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import disparate_impact_remover\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "willing-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PARAMS\n",
    "LABEL_COL, PROTECT_COLS, MODE, START_EPOCH, NUM_EPOCH, ID, NUM_TRIALS, NUM_PROXIES, FILE_PATH, VERBOSE, \\\n",
    "LR_RATE, UPDATE, WEIGHTS_INIT, UPDATE_LR, BATCH_SIZE, BALANCE = \"income\", [\"gender\"], 0, 0, 40, -1, 1, 0, \\\n",
    "                                                                \"../Datasets/adult_dataset/processed_adult.csv\", 1, \\\n",
    "                                                                0.001, \"cluster\", 0, 10, 1000, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-karen",
   "metadata": {},
   "source": [
    "#### Computes and split the dataset into train, validation and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "seeing-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics\n",
      "{0.0: gender\n",
      "0.0     (9798, 0.384)\n",
      "1.0    (15705, 0.616)\n",
      "dtype: object, 1.0: gender\n",
      "0.0    (1250, 0.149)\n",
      "1.0    (7163, 0.851)\n",
      "dtype: object}\n",
      "label: 0.0: 25503 samples (75.19%)\n",
      "label: 1.0: 8413 samples (24.81%)\n",
      "{0.0: gender\n",
      "0.0    (3228, 0.379)\n",
      "1.0    (5283, 0.621)\n",
      "dtype: object, 1.0: gender\n",
      "0.0     (419, 0.15)\n",
      "1.0    (2376, 0.85)\n",
      "dtype: object}\n",
      "label: 0.0: 8511 samples (75.28%)\n",
      "label: 1.0: 2795 samples (24.72%)\n",
      "---------- MAPPING ----------\n",
      "Train:  {(0.0,): 0, (1.0,): 1}\n",
      "Test:  {(1.0,): 0, (0.0,): 1}\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "balanced = {\"train_label_only\": True, \"test_label_only\": False, \"downsample\": True} if BALANCE else None\n",
    "\n",
    "\n",
    "df = load_dataset.get_data(FILE_PATH)\n",
    "df = load_dataset.minmax_scale(df)\n",
    "protected_index = df.columns.tolist().index(PROTECT_COLS[0])\n",
    "\n",
    "\n",
    "train_df, test_df = load_dataset.split_train_test(df, train=0.75)\n",
    "\n",
    "if balanced is not None:\n",
    "    train_df = load_dataset.balance_df(df, LABEL_COL, PROTECT_COLS, label_only=balanced[\"train_label_only\"],\n",
    "                            downsample=balanced[\"downsample\"])\n",
    "    test_df = load_dataset.balance_df(df, LABEL_COL, PROTECT_COLS, label_only=balanced[\"test_label_only\"],\n",
    "                            downsample=balanced[\"downsample\"])\n",
    "\n",
    "# Splitting dataset into train, test features\n",
    "print(\"Statistics\")\n",
    "load_dataset.statistics(train_df, LABEL_COL, PROTECT_COLS, verbose=1)\n",
    "load_dataset.statistics(test_df, LABEL_COL, PROTECT_COLS, verbose=1)\n",
    "\n",
    "train_dataset = load_dataset.Dataset(train_df, LABEL_COL, PROTECT_COLS)\n",
    "test_dataset = load_dataset.Dataset(test_df, LABEL_COL, PROTECT_COLS)\n",
    "\n",
    "\n",
    "print(\"---------- MAPPING ----------\")\n",
    "print(\"Train: \", train_dataset.mapping)\n",
    "print(\"Test: \", test_dataset.mapping)\n",
    "print(\"-----------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "occupied-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorable_label, unfavorable_label = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "funky-emerald",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]% training set changed\n",
      "[0.]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 1/11 [00:19<03:16, 19.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.5849991155139%\n",
      "Equalizing Odds: [[0.726, 0.927], [0.87, 0.792]]\n",
      "Weighted average odds difference 0.15653679462232445\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.33966651665538333\n",
      "[0.53748863]% training set changed\n",
      "[0.21883134]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 2/11 [00:39<02:57, 19.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.4877056430214%\n",
      "Equalizing Odds: [[0.724, 0.926], [0.871, 0.792]]\n",
      "Weighted average odds difference 0.15739536529276493\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3397979512928368\n",
      "[0.59258799]% training set changed\n",
      "[0.60326691]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 3/11 [00:59<02:39, 19.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.57615425437821%\n",
      "Equalizing Odds: [[0.725, 0.926], [0.871, 0.795]]\n",
      "Weighted average odds difference 0.15573642313815675\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.34106957761834544\n",
      "[0.6123848]% training set changed\n",
      "[0.63248654]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▋      | 4/11 [01:20<02:20, 20.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.54077480983548%\n",
      "Equalizing Odds: [[0.726, 0.925], [0.869, 0.795]]\n",
      "Weighted average odds difference 0.15382487174951356\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.34323667906907607\n",
      "[0.6123848]% training set changed\n",
      "[0.63248654]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 5/11 [01:40<02:00, 20.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.50539536529277%\n",
      "Equalizing Odds: [[0.725, 0.925], [0.87, 0.795]]\n",
      "Weighted average odds difference 0.15471431098531754\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3422621285890389\n",
      "[0.6123848]% training set changed\n",
      "[0.63248654]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 6/11 [01:59<01:39, 19.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 81.3992570316646%\n",
      "Equalizing Odds: [[0.723, 0.924], [0.87, 0.797]]\n",
      "Weighted average odds difference 0.15449159738192111\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3438661603195921\n",
      "[0.65929692]% training set changed\n",
      "[1.07567726]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▎   | 7/11 [02:19<01:19, 19.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 80.31133911197594%\n",
      "Equalizing Odds: [[0.689, 0.928], [0.89, 0.783]]\n",
      "Weighted average odds difference 0.18859808950999477\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3123858390100388\n",
      "[0.65929692]% training set changed\n",
      "[1.07567726]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 8/11 [02:39<00:59, 19.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 80.34671855651865%\n",
      "Equalizing Odds: [[0.692, 0.928], [0.886, 0.783]]\n",
      "Weighted average odds difference 0.18549858482221837\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3143936751472217\n",
      "[0.65929692]% training set changed\n",
      "[1.07567726]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 9/11 [02:58<00:39, 19.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 80.33787369538298%\n",
      "Equalizing Odds: [[0.691, 0.928], [0.888, 0.788]]\n",
      "Weighted average odds difference 0.18482221829117287\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3165276307580658\n",
      "[0.65929692]% training set changed\n",
      "[1.07567726]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 10/11 [03:17<00:19, 19.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 80.32902883424731%\n",
      "Equalizing Odds: [[0.691, 0.927], [0.887, 0.788]]\n",
      "Weighted average odds difference 0.18383433575092875\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3172584161914635\n",
      "[0.65929692]% training set changed\n",
      "[1.07567726]% training set changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 11/11 [03:36<00:00, 19.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 80.32902883424731%\n",
      "Equalizing Odds: [[0.693, 0.927], [0.885, 0.785]]\n",
      "Weighted average odds difference 0.18311887493366358\n",
      "Before - disparate impact: 0.3703427890088159\n",
      "After - disparate impact: 0.3189285105488234\n"
     ]
    }
   ],
   "source": [
    "accs, avg_odd_difference = [], []\n",
    "for level in tqdm(np.linspace(0., 1., 11)):\n",
    "    di = disparate_impact_remover.DisparateImpactRemover(repair_level=level)\n",
    "    train_repd = di.fit_transform(train_dataset, protected_index)\n",
    "    test_repd = di.fit_transform(test_dataset, protected_index)\n",
    "    \n",
    "    X_tr = np.delete(train_repd.features, protected_index, axis=1)\n",
    "    X_te = np.delete(test_repd.features, protected_index, axis=1)\n",
    "    y_tr = train_repd.label.ravel()\n",
    "    print(f\"{np.sum((train_dataset.features != train_repd.features)).reshape(-1)/len(train_dataset.features.reshape(-1))*100}% training set changed\")\n",
    "    print(f\"{np.sum((test_dataset.features != test_repd.features)).reshape(-1)/len(test_dataset.features.reshape(-1))*100}% training set changed\")\n",
    "    \n",
    "    lmod = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "    lmod.fit(X_tr, y_tr)\n",
    "    \n",
    "    test_repd_pred = test_repd.copy()\n",
    "    test_repd_pred.label = lmod.predict(X_te)\n",
    "    \n",
    "    print()\n",
    "\n",
    "    acc = np.sum(test_repd_pred.label.reshape(-1) == test_repd.label.reshape(-1))/len(test_dataset.label)\n",
    "    odds = fairness_metrics.equalizing_odds(test_repd_pred.label, test_repd.label,\n",
    "                                                           test_repd.protect)\n",
    "    diffs = [max(odd) - min(odd) for odd in odds]\n",
    "    print(f\"Accuracy: {acc*100}%\")\n",
    "    print(f\"Equalizing Odds: {odds}\")\n",
    "    print(f\"Weighted average odds difference\", np.average(diffs, weights=[np.sum(test_repd_pred.label == unfavorable_label), np.sum(test_repd_pred.label == favorable_label)]))\n",
    "    print(f\"Before - disparate impact: {disparate_impact(test_repd.label, test_repd.protect, 0, 1)}\")\n",
    "    print(f\"After - disparate impact: {disparate_impact(test_repd_pred.label, test_repd_pred.protect, 0, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "traditional-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(predictions, group, privilege, favorable):\n",
    "    p, up, p_f, up_f = 0, 0, 0, 0\n",
    "    for pred, g in zip(predictions, group):\n",
    "        if g == privilege:\n",
    "            if pred == favorable:\n",
    "                p_f += 1\n",
    "            p += 1\n",
    "        else:\n",
    "            if pred == favorable:\n",
    "                up_f += 1\n",
    "            up += 1\n",
    "    return (up_f/up)/(p_f/p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
